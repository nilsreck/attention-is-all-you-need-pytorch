\section{Introduction}

The Transformer model~\cite{vaswani2017attention} established the foundation for more performant and context-aware sequence transduction by removing the recurrent or convolutional means of previous state-of-the-art models.
This is mainly due to the Transformer's ability to process multiple sequences at once.
Up until today, the Transformer model remains the architecture of choice for top-performing large language models, like GPT-4o. \\
This report showcases my attempt to implement a custom Transformer model for a German-English translation task and aligns with the practicals conducted during the course.
In particular, it focuses on providing the reader with detailed knowledge about its components and their interplay, as well as my personal insights and struggles during development and training.
Thus, the report commences with a methodolgy section, explaining the modular components of a Transformer and the overall architecture.

% Study the model in the paper Attention is all you need. Write down the
% structurg of the proposed model.
