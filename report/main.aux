\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vaswani2023attentionneed}
\citation{press2017usingoutputembeddingimprove}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{1}{section.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{add info about alignment of sequences (maybe add to training section)}{1}{section*.1}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{20088094}{12217704}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Embedding Layers}{1}{subsection.2.1}\protected@file@percent }
\citation{he2015deepresiduallearningimage}
\citation{ba2016layernormalization}
\@writefile{tdo}{\contentsline {todo}{How does the model differentiate between embedding and position?}{2}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid2}{31409438}{41872861}
\pgfsyspdfmark {pgfid5}{34243870}{41885149}
\pgfsyspdfmark {pgfid6}{36357406}{41661235}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Encoder Stack}{2}{subsection.2.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{why?}{2}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{31409438}{15235667}
\pgfsyspdfmark {pgfid10}{34243870}{15247955}
\pgfsyspdfmark {pgfid11}{36357406}{15024041}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Decoder Stack}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Attention}{3}{subsection.2.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Explain how multiple atttention heads help}{3}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid12}{20088094}{38018075}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Position-wise Feed-Forward Layer}{3}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Optimization Techniques}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Learning Rate Scheduler}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Optimizer}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Training}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{4}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Questions}{4}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Practical 4}{4}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Practical 5}{4}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Positional Encoding}{4}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Encoder}{4}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Position-Wise Feed-Forward Networks}{5}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Normalization Layer}{5}{section.10}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Cite Layer Normalization paper}{5}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid14}{20088094}{14071813}
\@writefile{toc}{\contentsline {section}{\numberline {11}Optimizer Initialization}{5}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}\texttt  {AdamW}}{5}{subsection.11.1}\protected@file@percent }
\newlabel{eq:mean_var}{{4}{6}{\texttt {AdamW}}{equation.11.4}{}}
\newlabel{eq:mean_var@cref}{{[equation][4][]4}{[1][6][]6}}
\newlabel{eq:moments}{{5}{6}{\texttt {AdamW}}{equation.11.5}{}}
\newlabel{eq:moments@cref}{{[equation][5][]5}{[1][6][]6}}
\newlabel{eq:weight_decay}{{6}{6}{\texttt {AdamW}}{equation.11.6}{}}
\newlabel{eq:weight_decay@cref}{{[equation][6][]6}{[1][6][]6}}
\newlabel{eq:update}{{7}{6}{\texttt {AdamW}}{equation.11.7}{}}
\newlabel{eq:update@cref}{{[equation][7][]7}{[1][6][]6}}
\@writefile{tdo}{\contentsline {todo}{Where do we apply dropout?}{7}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid15}{20088094}{43356069}
\@writefile{tdo}{\contentsline {todo}{What are learnable parameters in a transformer model?}{7}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{20088094}{42223753}
\@writefile{tdo}{\contentsline {todo}{Inclued questions from tests}{7}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid17}{20088094}{41091437}
\bibdata{references}
\bibcite{ba2016layernormalization}{BKH16}
\bibcite{he2015deepresiduallearningimage}{HZRS15}
\bibcite{press2017usingoutputembeddingimprove}{PW17}
\bibstyle{alpha}
\gdef \@abspage@last{8}
