\section{Results}\label{sec:results}

This section provides the results of the CPU vs. GPU comparison, as well as the perfomance of the Transformer model on the translation task.

\subsection{GPU versus CPU Training}

\cref{tab:comparison} illustrates the results of the perfomance comparison between CPU and GPU training.
The GPU significantly accelerates the overall training process by a facor of 8.07.
Accordingly, the GPU processes a single epoch, as well as a forward pass, faster by approximately the same margin.
The GPU achieves the most significant speed-up (20x) during the backward pass.
This highlights the GPU's superior efficiency in handling computationally expensive tasks, such as gradient computation, which heavily rely on parallelized matrix calculations.
Surprisingly, the GPU uses 38 times less memory per epoch compared to the CPU, which can mainly be attributed to the small batch size of 32 for both setups.\\
Due to approaching deadlines and long queues on the high performance cluster (HPC), I postpone further optimizations of the GPU codebase.
For instance, offloading BLEU score calculations to the CPU, combined with mixed-precision training and other optimizations, can approximately halve overall training time--a speedup that has been observed in practical 11.\\
\begin{table}[ht]
    \centering
    \begin{tabular}{lccc}
        \toprule
        \textbf{Metric} & \textbf{CPU} & \textbf{GPU} & \textbf{CPU to GPU Ratio} \\
        \midrule
        Training time (hours)       & 3.0017 & 0.3717 & 8.07 \\
        Avg. Epoch times (seconds)       & 2161.24 & 267.63 & 8.07 \\
        Avg. Forward pass times (seconds)& 0.0770 & 0.0088 & 8.75 \\
        Avg. Backward pass time (seconds)& 0.2020 & 0.0101 & 20 \\
        Avg. Single step time (seconds)  & 0.2790 & 0.0189 & 14.76  \\
        Allocated memory per epoch (MB)       & 32998.0  & 865.91 & 38.1 \\
        \bottomrule
    \end{tabular}
    \caption{Performance comparison of CPU vs. GPU}
    \label{tab:comparison}
\end{table}
While the performance benefits speak for themselves, GPU training entails some disadvantages.
Working on the HPC, I experienced long queues before the jobs could start, as well as complexity in setting up the code and accompanying libraries to run on the GPU nodes.
This results in longer feedback cycles because each attempt requires submitting a new job and waiting.
If errors occur, they only got discovered after the job queue processed the experiment, further extending debugging time.
Additionally, estimating the memory resources for optimizing throughput was time-consuming and often required trial and error, especially without easy access to a GPU for testing.

\subsection{Estimation of Memory Requirements}
For estimating memory requirements, you not only have to account for the amout of model parameters, but also the optimizer states, activation storage during the forward and backward passes to ensure proper gradient computation, as well as additional buffers used during matrix operations, softmax computations, etc.
PyTorch uses \texttt{float32} precision by default, meaning it uses 4 bytes to represent a single parameter.
The full Transformer model comprises \(\sim\) 95 million parameters, resulting in \(\sim\) 360MB of storage.
However, that does not account for the optimizer states, which contribute two extra values (first and second moment) per parameter (excluding bias terms), effectively tripling the memory requirements.
\subsection{Machine Translation}
